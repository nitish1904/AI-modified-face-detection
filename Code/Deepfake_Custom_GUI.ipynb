{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# Rest of your code goes here.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a TensorFlow session and set the GPU device\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Specify the GPU device index to use (e.g., 1 for GPU 1)\n",
    "    gpu_index = 1\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[gpu_index], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Rest of your code goes here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import os\n",
    "from keras.datasets import fashion_mnist, cifar100\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from keras import optimizers\n",
    "from keras.layers.core import Lambda\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path=\"C:/Users/year1/Downloads/Dataset2\"\n",
    "#path=\"C:/Users/gaura/Downloads/Dataset2\"\n",
    "path=\"C:/Work2/data\"\n",
    "\n",
    "face_types=os.listdir(path)\n",
    "print(face_types)\n",
    "\n",
    "print(\"types of faces found:\",len(face_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces=[]\n",
    "\n",
    "for item in face_types:\n",
    "    all_faces=os.listdir(path + '/' + item)\n",
    "\n",
    "    for face in all_faces:\n",
    "        faces.append((item,str(path+'/'+item)+'/'+face))\n",
    "        #print(faces[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dataframe        \n",
    "faces_df = pd.DataFrame(data=faces, columns=['face type', 'image'])\n",
    "print(faces_df.head())\n",
    "print(faces_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore if resized exists\n",
    "#creates resized folder\n",
    "import cv2\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "#path = \"C:/Users/year1/Downloads/Dataset2\"\n",
    "#path=\"C:/Users/gaura/Downloads/Dataset2\"\n",
    "path=\"D:/Work/data\"\n",
    "im_size = 227\n",
    "batch_size = 380  # adjust batch size as needed\n",
    "\n",
    "def image_generator():\n",
    "    for i in face_types:\n",
    "        data_path = os.path.join(path, str(i))\n",
    "        filenames = os.listdir(data_path)\n",
    "        for j in range(0, len(filenames), batch_size):\n",
    "            batch_filenames = filenames[j:j+batch_size]\n",
    "            batch_images = []\n",
    "            batch_labels = []\n",
    "            for f in batch_filenames:\n",
    "                img = cv2.imread(os.path.join(data_path, f))\n",
    "                if img is None:\n",
    "                    print(f\"Error: failed to read {os.path.join(data_path, f)}\")\n",
    "                    continue\n",
    "                img = cv2.resize(img, (im_size, im_size))\n",
    "                filename = os.path.splitext(f)[0] + '.jpg'  # change extension to .jpg\n",
    "                filepath = os.path.join(data_path, 'resized_Alexnet', filename)  # create output path\n",
    "                cv2.imwrite(filepath, img)  # write resized image to disk\n",
    "                batch_images.append(filepath)  # append file path to batch\n",
    "                batch_labels.append(i)\n",
    "            yield batch_images, np.array(batch_labels)\n",
    "\n",
    "# create output directories\n",
    "for i in face_types:\n",
    "    os.makedirs(os.path.join(path, str(i), 'resized_AlexNet'), exist_ok=True) # change for different network\n",
    "\n",
    "# Example usage\n",
    "gen = image_generator()\n",
    "for i in range(101):  # load 10 batches\n",
    "    batch_images, batch_labels = next(gen)\n",
    "    print(f\"Loaded batch {i+1} with {len(batch_images)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore if h5 exists\n",
    "#creates images.h5\n",
    "import os \n",
    "import cv2 \n",
    "import numpy as np \n",
    "import h5py \n",
    "#path = \"C:/Users/year1/Downloads/Dataset2/\" \n",
    "#path=\"C:/Users/gaura/Downloads/Dataset2\"\n",
    "path=\"C:/Work2/data\"\n",
    "im_size = 227 \n",
    "images = [] \n",
    "for i in face_types: \n",
    "    data_path = os.path.join(path, str(i), 'Augmented') \n",
    "    filenames = os.listdir(data_path) \n",
    "    for f in filenames: \n",
    "        filepath = os.path.join(data_path, f) \n",
    "        images.append(filepath) \n",
    "with h5py.File('images_AlexNet2.h5', 'w') as f: \n",
    "    dset = f.create_dataset('images', shape=(len(images), im_size, im_size, 3), dtype='float16')\n",
    "    for i, filepath in enumerate(images): \n",
    "        img = cv2.imread(filepath) \n",
    "        img = cv2.resize(img, (im_size, im_size)) \n",
    "        img = img.astype('float16') / 255.0 \n",
    "        dset[i] = img \n",
    "with h5py.File('images_AlexNet2.h5', 'r') as f: \n",
    "    dset = f['images'] \n",
    "    for i in range(len(images)): \n",
    "        img = dset[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Convert labels to numerical values using label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(faces_df['face type'].values)\n",
    "\n",
    "# Perform one hot encoding on the numerical labels\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "y_onehot = onehot_encoder.fit_transform(y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(96, (11,11), strides=(4,4), activation='relu', input_shape=(227,227,3)))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "model.add(Conv2D(256, (5,5), strides=(1,1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "model.add(Conv2D(384, (3,3), strides=(1,1), activation='relu'))\n",
    "model.add(Conv2D(384, (3,3), strides=(1,1), activation='relu'))\n",
    "model.add(Conv2D(256, (3,3), strides=(1,1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_test=\"C:/Users/year1/Downloads/Dataset_Copy_test\"\n",
    "#path_test=\"C:/Users/gaura/Downloads/Dataset_Copy_test3\"\n",
    "path_test=\"C:/WORK/Dataset_Copy_test3\"\n",
    "face_types_test=os.listdir(path_test)\n",
    "print(face_types_test)\n",
    "\n",
    "print(\"types of faces found:\",len(face_types_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_test=[]\n",
    "\n",
    "for item in face_types_test:\n",
    "    all_faces_test=os.listdir(path_test + '/' + item)\n",
    "\n",
    "    for face in all_faces_test:\n",
    "        faces_test.append((item,str(path_test+'/'+item)+'/'+face))\n",
    "        #print(faces[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_df_test = pd.DataFrame(data=faces_test, columns=['face type', 'image'])\n",
    "print(faces_df_test.head())\n",
    "print(faces_df_test.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#path = \"C:/Users/year1/Downloads/Dataset_Copy_test\"\n",
    "#path =\"C:/Users/gaura/Downloads/Dataset_Copy_test3\"\n",
    "path=\"C:/WORK/Dataset_Copy_test3\"\n",
    "im_size = 227\n",
    "face_types = ['Fake','Real']\n",
    "\n",
    "label_map_test = {label: idx for idx, label in enumerate(face_types)}\n",
    "\n",
    "images_test = []\n",
    "labels_test = []\n",
    "\n",
    "for label in face_types:\n",
    "    data_path = os.path.join(path, label)\n",
    "    filenames = [os.path.join(data_path, f) for f in os.listdir(data_path)]\n",
    "   \n",
    "    for filename in filenames:\n",
    "        img = cv2.imread(filename)\n",
    "        img = cv2.resize(img, (im_size, im_size))\n",
    "        images_test.append(img)\n",
    "        labels_test.append(label_map_test[label])\n",
    "\n",
    "images_test = np.array(images_test, dtype=np.float32)\n",
    "labels_test = np.array(labels_test, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test = np.array(images_test)\n",
    "\n",
    "images_test.shape\n",
    "\n",
    "images_test = images_test.astype('float16') / 255.0\n",
    "\n",
    "images_test.shape\n",
    "\n",
    "#images = np.array(images, dtype='float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Convert labels to numerical values using label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y_test = label_encoder.fit_transform(faces_df_test['face type'].values)\n",
    "\n",
    "# Perform one hot encoding on the numerical labels\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "y_onehot_test = onehot_encoder.fit_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test, y_onehot_test = shuffle(images_test, y_onehot_test, random_state=7)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(images_test, y_onehot_test, test_size=0.9, random_state=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "# open the .h5 file and get the dataset shape\n",
    "with h5py.File('images_AlexNet2.h5', 'r') as file:\n",
    "    num_images = file['images'].shape[0]\n",
    "batch_size = 190\n",
    "num_epochs = 1\n",
    "\n",
    "train_losses=[]\n",
    "val_losses=[]\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, 95000, batch_size):\n",
    "        with h5py.File('images_AlexNet2.h5', 'r') as file:\n",
    "            fake_images_batch = file['images'][i:i+batch_size]\n",
    "            real_images_batch = file['images'][95000+i:95000+i+batch_size]\n",
    "            images_batch = np.concatenate([fake_images_batch, real_images_batch])\n",
    "            fake_labels_batch = y_onehot[i:i+batch_size]\n",
    "            real_labels_batch = y_onehot[95000+i:95000+i+batch_size]\n",
    "            labels_batch = np.concatenate([fake_labels_batch, real_labels_batch])\n",
    "            print(\"processing\",(i/190)+1,\"epoch\",epoch+1)\n",
    "            history=model.train_on_batch(images_batch, labels_batch)\n",
    "            train_losses.append(history[0])\n",
    "            val_loss=model.evaluate(x_test,y_test)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "plt.plot(train_losses,label='Training Loss')\n",
    "plt.plot(val_losses,label='Validation Loss')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()           \n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:/Work2/model_AlexNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(x_train)\n",
    "\n",
    "# Convert the predictions to binary labels\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_train, axis=1)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('C:/Work2/model_Custom.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fake', 'Real']\n",
      "types of faces found: 2\n"
     ]
    }
   ],
   "source": [
    "#path_test=\"C:/Users/year1/Downloads/Dataset_Copy_test\"\n",
    "#path_test=\"C:/Users/gaura/Downloads/Dataset_Copy_test3\"\n",
    "path_test=\"C:/WORK/Dataset_Copy_test4\"\n",
    "face_types_test=os.listdir(path_test)\n",
    "print(face_types_test)\n",
    "\n",
    "print(\"types of faces found:\",len(face_types_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_test=[]\n",
    "\n",
    "for item in face_types_test:\n",
    "    all_faces_test=os.listdir(path_test + '/' + item)\n",
    "\n",
    "    for face in all_faces_test:\n",
    "        faces_test.append((item,str(path_test+'/'+item)+'/'+face))\n",
    "        #print(faces[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  face type                                              image\n",
      "0      Fake  C:/WORK/Dataset_Copy_test4/Fake/0052ETBQFB_aug...\n",
      "1      Fake  C:/WORK/Dataset_Copy_test4/Fake/0052ETBQFB_aug...\n",
      "2      Fake  C:/WORK/Dataset_Copy_test4/Fake/0052ETBQFB_aug...\n",
      "3      Fake  C:/WORK/Dataset_Copy_test4/Fake/053UBPVSLY_aug...\n",
      "4      Fake  C:/WORK/Dataset_Copy_test4/Fake/053UBPVSLY_aug...\n",
      "     face type                                              image\n",
      "5995      Real  C:/WORK/Dataset_Copy_test4/Real/67_0_0_2017010...\n",
      "5996      Real  C:/WORK/Dataset_Copy_test4/Real/67_0_0_2017010...\n",
      "5997      Real  C:/WORK/Dataset_Copy_test4/Real/67_0_0_2017010...\n",
      "5998      Real  C:/WORK/Dataset_Copy_test4/Real/67_0_0_2017010...\n",
      "5999      Real  C:/WORK/Dataset_Copy_test4/Real/67_0_0_2017010...\n"
     ]
    }
   ],
   "source": [
    "faces_df_test = pd.DataFrame(data=faces_test, columns=['face type', 'image'])\n",
    "print(faces_df_test.head())\n",
    "print(faces_df_test.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#path = \"C:/Users/year1/Downloads/Dataset_Copy_test\"\n",
    "#path =\"C:/Users/gaura/Downloads/Dataset_Copy_test3\"\n",
    "path=\"C:/WORK/Dataset_Copy_test4\"\n",
    "im_size = 128\n",
    "face_types = ['Fake','Real']\n",
    "\n",
    "label_map_test = {label: idx for idx, label in enumerate(face_types)}\n",
    "\n",
    "images_test = []\n",
    "labels_test = []\n",
    "\n",
    "for label in face_types:\n",
    "    data_path = os.path.join(path, label)\n",
    "    filenames = [os.path.join(data_path, f) for f in os.listdir(data_path)]\n",
    "   \n",
    "    for filename in filenames:\n",
    "        img = cv2.imread(filename)\n",
    "        img = cv2.resize(img, (im_size, im_size))\n",
    "        images_test.append(img)\n",
    "        labels_test.append(label_map_test[label])\n",
    "\n",
    "images_test = np.array(images_test, dtype=np.float32)\n",
    "labels_test = np.array(labels_test, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 128, 128, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_test = np.array(images_test)\n",
    "\n",
    "images_test.shape\n",
    "\n",
    "images_test = images_test.astype('float16') / 255.0\n",
    "\n",
    "images_test.shape\n",
    "\n",
    "#images = np.array(images, dtype='float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Convert labels to numerical values using label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y_test = label_encoder.fit_transform(faces_df_test['face type'].values)\n",
    "\n",
    "# Perform one hot encoding on the numerical labels\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "y_onehot_test = onehot_encoder.fit_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test, y_onehot_test = shuffle(images_test, y_onehot_test, random_state=7)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(images_test, y_onehot_test, test_size=0.9, random_state=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 7s 48ms/step - loss: 0.0237 - accuracy: 0.9883\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "precision = precision_score(y_test_classes, y_pred_classes)\n",
    "recall = recall_score(y_test_classes, y_pred_classes)\n",
    "f1 = f1_score(y_test_classes,y_pred_classes)\n",
    "auroc = roc_auc_score(y_test_classes,y_pred_classes)\n",
    "\n",
    "print(\"Accuracy is =\", accuracy*100,\"%\")\n",
    "print(\"Precision is =\", precision*100,\"%\")\n",
    "print(\"Recall is =\", recall*100,\"%\")\n",
    "print(\"F1-Score is =\", f1*100,\"%\")\n",
    "print(\"AUROC is =\", auroc*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       308\n",
      "           1       0.99      0.98      0.99       292\n",
      "\n",
      "    accuracy                           0.99       600\n",
      "   macro avg       0.99      0.99      0.99       600\n",
      "weighted avg       0.99      0.99      0.99       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(x_train)\n",
    "\n",
    "# Convert the predictions to binary labels\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_train, axis=1)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (3.33.1)\n",
      "Requirement already satisfied: pydub in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (3.7.1)\n",
      "Requirement already satisfied: altair>=4.2.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (5.0.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (1.5.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (1.23.5)\n",
      "Requirement already satisfied: semantic-version in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (0.3.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (6.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (9.4.0)\n",
      "Requirement already satisfied: python-multipart in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (0.0.6)\n",
      "Requirement already satisfied: httpx in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (0.24.1)\n",
      "Requirement already satisfied: requests in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (2.28.1)\n",
      "Requirement already satisfied: orjson in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (3.9.0)\n",
      "Requirement already satisfied: gradio-client>=0.2.4 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (0.2.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.14.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (0.15.1)\n",
      "Requirement already satisfied: websockets>=10.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (11.0.3)\n",
      "Requirement already satisfied: markupsafe in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (2.1.1)\n",
      "Requirement already satisfied: mdit-py-plugins<=0.3.3 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (0.3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (3.8.3)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (0.22.0)\n",
      "Requirement already satisfied: pygments>=2.12.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (2.15.1)\n",
      "Requirement already satisfied: fastapi in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (0.96.0)\n",
      "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (2.2.0)\n",
      "Requirement already satisfied: pydantic in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (1.10.8)\n",
      "Requirement already satisfied: aiofiles in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (23.1.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio) (4.4.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from altair>=4.2.0->gradio) (4.17.3)\n",
      "Requirement already satisfied: toolz in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio-client>=0.2.4->gradio) (22.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from gradio-client>=0.2.4->gradio) (2023.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from huggingface-hub>=0.14.0->gradio) (3.12.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from huggingface-hub>=0.14.0->gradio) (4.65.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from pandas->gradio) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from pandas->gradio) (2.8.2)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from uvicorn>=0.14.0->gradio) (8.0.4)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from aiohttp->gradio) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from aiohttp->gradio) (1.8.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from aiohttp->gradio) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from aiohttp->gradio) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from aiohttp->gradio) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from aiohttp->gradio) (6.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from aiohttp->gradio) (1.2.0)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from fastapi->gradio) (0.27.0)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from httpx->gradio) (0.17.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from httpx->gradio) (2022.12.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from httpx->gradio) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from httpx->gradio) (3.4)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from matplotlib->gradio) (5.12.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from matplotlib->gradio) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from matplotlib->gradio) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from matplotlib->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from matplotlib->gradio) (4.39.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from matplotlib->gradio) (1.4.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from requests->gradio) (1.26.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from click>=7.0->uvicorn>=0.14.0->gradio) (0.4.6)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.5.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->gradio) (3.11.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.18.0)\n",
      "Requirement already satisfied: uc-micro-py in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio) (1.0.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->gradio) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img):\n",
    "    img_3d=img.reshape(-1,128,128,3)\n",
    "    prediction=model.predict(img_3d)[0]\n",
    "    return {face_types[i]: float (prediction[i]) for i in range(2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\gradio\\inputs.py:259: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "C:\\Users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\gradio\\inputs.py:262: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  super().__init__(\n",
      "C:\\Users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\gradio\\outputs.py:197: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n",
      "C:\\Users\\arjun\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\gradio\\outputs.py:200: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
      "  super().__init__(num_top_classes=num_top_classes, type=type, label=label)\n",
      "C:\\Users\\arjun\\AppData\\Local\\Temp\\ipykernel_5292\\2571677612.py:4: UserWarning: `capture_session` parameter is deprecated, and it has no effect\n",
      "  gr.Interface(fn=predict_image, inputs=image, outputs=label, capture_session=True).launch(debug=\"True\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image=gr.inputs.Image(shape=(128,128))\n",
    "label=gr.outputs.Label(num_top_classes=2)\n",
    "\n",
    "gr.Interface(fn=predict_image, inputs=image, outputs=label, capture_session=True).launch(debug=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
